[
["index.html", "Data Science for Petroleum Production Engineers Preface", " Data Science for Petroleum Production Engineers Alfonso R. Reyes 2017-06-07 Preface This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). For now, you have to install the development versions of bookdown from Github: devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need to install XeLaTeX. "],
["part-1-data-science-for-petroleum-production-engineering.html", "1 Part 1: Data Science for Petroleum Production Engineering 1.1 The Old vs the New 1.2 Why does it take so long to build optimization models? 1.3 Data Structures are our friends 1.4 Remember Garbage In, Garbage Out 1.5 The Python notebooks are a fit for production engineers", " 1 Part 1: Data Science for Petroleum Production Engineering 1.1 The Old vs the New In the last century, the production engineer built the well models one by one and analyzed the results also one by one. With the ubiquity of the personal computer, desktops and laptops, an unimaginable computational power has been put in our hands. But we need the right tools! Why -if we communicate data at gigabits per second-, are we still using a tool of the era of bits per second? The spreadsheet was invented in the 80’s and was a great invention. The beauty of it is that you can produce results right away. We are very thankful to Lotus 1-2-3 and Microsoft Excel for that. But let us remember that it was the 80’s –there was not internet, no tablets, data moved at 2400 bps, and real-time data acquisition was constrained to a handful of fields. Today, well data comes in gigabytes per minute and we know it is not humanly possible to tackle all the information to put it at good use. The answer of this century is to that is start using automation, artificial intelligence, statistics, machine learning but first of all, data science. These are the keywords of the future. The future of the petroleum engineer. 1.2 Why does it take so long to build optimization models? One of the things that always intrigued the production managers what is it that takes so long to build well models and a network models? One of the causes is that we have to enter the data manually; we have to double and triple check the data we are entering, calibrate and match the model; and – the most important of all-, we do enter the data without a context. What does that mean? It means we work on a well model in isolation without having the tools to validate our well data in the context of the field data or of other wells data (neighbors). Then when we have all our 77 or 177 wells ready, we received fresh well test data that contradicts earlier well tests! Go back to rework some models. Part of this conundrum is not the production engineer’s fault; it is just the way that well optimization software works or has been built: to attack a well one at a time and disconnected from the test data source. At Petronas we have been using for a while Python scripts to help to address the problem of single well modeling in a radical different way: by building well models with multiwell scanning, validation and analysis. With these techniques the engineer minimizes the manual data entering, validation, calibration and data qualification. This by itself represents a major advantage over the traditional way of doing well and network modeling. The additional power and discovery of oil gains from production optimization comes from applying basic statistics to the results or the calculations or simulation runs.  The plots that you see in this post are just few samples of the work of well and network modeling on a field. I have changed names and numbers to make the exercise neutral. None of this is earth shattering new; it has been around for years but the digital tools that are making technology companies successful are taking time to take off in the production engineering field. Well, first, data science is hard. But enormously gratifying when you find hidden oil. 1.3 Data Structures are our friends One of the keys in data science is to get accustomed to analyze well production data by using dynamic tables. There is no best tool for analyzing production engineering data than Python Pandas. The pandas tables (yes, it is written in lowercase) are a magnificent object to manipulate, arrange, organize, calculate, clean, select, filter, analyze and plotting our production data. We created the Petronas PTech Engineering Library that includes dozens of scripts that make use of pandas and other Pythons packages such as numpy, scipy, matplotlib, PyQt4, pyqtgraph, bokeh, traits, etc.  With the help of the libraries the engineer is able to analyze the well model data faster and in a more reliably way since all these tasks are done by algorithms written in Python, the world’s leading scripting language for scientists and engineers. And, it is open source. Your are curious? This is how a simple statement looks like. From the data we can say that the biggest producers are wells producing by gas lift with an average of 944 blpd (barrels of liquid per day), a maximum of 2421 blpd in a total of 98 wells. The lowest producer is at 100 blpd. 1.4 Remember Garbage In, Garbage Out In next posts I will be showing simple Python and pandas scripts for petroleum production engineering. What we see in the next plot is a plotting technique for quality control of the well test data to be used in the well models. Before we run the models it is recommended that you run some scripts to qualify the data such as finding outliers or data points that do not belong there. 1.5 The Python notebooks are a fit for production engineers The Python notebooks look ideal for the application of data science to well, network modeling and production optimization. There are many ways of running Python but I find the notebook the best method to transmit knowledge and share solutions with colleagues. The Python notebooks -lately renamed as Jupyter -, are widely known in the engineering community. You shouldn’t have any trouble finding assistance online. The same applies to Python. My favorite is stackoverflow.com. There are hundreds of engineering and scientific libraries around that will help to makes your production engineering job more efficient, accurate, profitable and fun. The Python notebook opens in a browser but if you want to make long and advanced scripts for petroleum engineering, there are plenty of good development applications or IDEs out there: Spyder, PyCharm and Eclipse, just to mention a few. "],
["part-2-data-science-for-petroleum-production-engineering.html", "2 Part 2: Data Science for Petroleum Production Engineering 2.1 Introduction 2.2 Multiwell Scanning 2.3 Dataframes 2.4 Excel 2.5 Scripting in Python 2.6 What are we learning so far?", " 2 Part 2: Data Science for Petroleum Production Engineering 2.1 Introduction In the past session we got an introduction to the multiwell statistics package showing a few of the things that we can do with the Petronas PTech Engineering Library. Now, we will explore some more functionality. It is incredible the huge amount of information when we get from all the wells in one scan pass. The data starts to have sense. A well in isolation or standalone doesn’t tell used much about the field or differences between well parameters from well to well. This is where the power of the multiwell scanning resides.  2.2 Multiwell Scanning The multiwell scanning is the process by which we use a Python script to automatically open all the well models in the background, pulling the user-defined parameters and create an output file where the rows are the wells and the well parameters are the columns. The scanning open the optimization software, which could be Petex Prosper, AppSmiths WinGLUE or any other that has a way to share its variables outside the application. In the case of Petronas, we adopted as a standard both. In this example I will use use Prosper. This is how a file with the input variables look like: These are few of the variables that we want to pull from each of the well models to be scanned. Note that the first 7 columns belong to the decomposition of the Petex OpenServer variables. I created this input file to make possible a repeatable selection process. In one of the datasets we will see 94 variable-columns; in other maybe less than 40. You can also have a set of input workbooks; one for PVT analysis, another for well test, or gas lift, or IPR or VLP selection. In another post I will enter in detail about this input worksheet. 2.3 Dataframes After the script finishes gathering data from the last well you will end up with an output file. The tabular form of the data in that output file is what is called in Python pandas a dataframe. The table looks like this: 2.4 Excel Yes, it is Excel. But we just use it as a legacy so any production technologist can see the output without much complication. Some have questioned why we do all this data processing with Python instead of using Excel. The question is very simple, and I think you will quickly understand if you have ever worked with datasets in Excel. I will just cite few of the inconveniences: (1) the macros VBA are alright if you are writing less than a hundred of lines of code; (2) the code in VBA is difficult to maintain and there is no version control like with git or other; (3) Microsoft VBA has its own way of doing things and you have to learn a lot about the internals of the MS libraries if you want to do little above of the ordinary calculations and plotting; (4) VBA code is difficult to share with colleagues and when you make a change or update the code you have to send again the big workbook, in other words there is no updating process embedded within Excel and VBA. Don’t get me wrong. I have done terrific things with Excel VBA but it is painful by the lack of an engineering or scientific community behind as is the case with Python. Let’s say that Excel is good at table visualization and anybody can open and understand it. But as you get immersed with Python and pandas you will see that using Excel as data containers is purely optional; there are other powerful data structures available out there. 2.5 Scripting in Python The Python script that open the well models and pulls the data is this: Each of the lines in the script is explained through a comment above. But let’s briefly explain what this script does. What we are trying to achieve is reading all the Prosper well models located under the folder PISC. You are interested in reading some variables from these models and putting them in a table-like structure for statistical analysis later. These variables have been defined in the input workbook –explained above.  Loading the dataset Now, you have generated yourself a dataset. This dataset contains the data of 100 wells that was just generated by the application multiwell scanner. Let’s load the dataset with this script: Immediately with the execution we get some information about the well collection: Plotting To start plotting, we can just write: For artificial lift: For the IPR methods that were used on each of the well models: 0 And for the PVT correlations: 2.6 What are we learning so far? At this moment you may be wondering: well modeling is hard; it takes a lot of work. So many variables to take care of. Yes, it is. That’s why getting a network model ready for scenarios and simulation takes so long.  The advantage here, with the Python PTech Library, is that we are acting on multiple wells; not just one. There is a significant reduction in time and improvement in the quality of the data by tackling the problem in this way. But requires a toolbox: the toolbox of the data scientist. You are now using the bleeding edge of the digital tools available to the brightest minds in the world to find more oil; faster and efficiently. "],
["r-and-the-search-of-the-ideal-language-for-petroleum-engineering.html", "3 “R” and the search of the ideal language for petroleum engineering 3.1 The fun of the 21st century 3.2 What is R? 3.3 Ploting 3.4 Packages 3.5 Foreign languages 3.6 Reproducible 3.7 GUI not 3.8 Where is everybody 3.9 The bottom line", " 3 “R” and the search of the ideal language for petroleum engineering img 3.1 The fun of the 21st century I have to confess my sin. I am coming from writing thousands of lines of Python code for a well modeling and optimization project. I did Exploratory Data Analysis for the resulting well models and applied statistics using Python, pandas, matplotlib, SciPy and NumPy. I went full throttle and didn’t look behind. Got the results, the production engineering team increased the oil production we were looking for. All went fine, with the exception of the sin of not exploring the other alternative: doing the work with “R”. If you haven’t heard about R you are missing the fun of the 21st century: data science. I might not be totally to blame though. Python is a relatively easy to learn scripting language, fast prototyping applications and producing quick results. Also, it has under its domain pretty good engineering and scientific tools. Like the ones I cited above. Plus the statistical packages that have been flourishing over the years. 3.2 What is R? On the other hand, there is R, another programming language with the peculiar feature of having been invented by statisticians about couple of decades ago. R is the preferred open-source language when it comes to publishing research, doctoral papers, statistical analysis, supervised and unsupervised machine learning, regression analysis, forecasting, exploratory data analysis, multivariate plotting or visualization. R can be intimidating. Didn’t I tell you that its users are mostly PhDs? R is different of any other language I have seen over the years. And that comes, I believe, from its intense focus on the data, data analysis, statistics and vector oriented operations. After few months spent on learning and working with R, I can tell you that any sweat was worth every penny. It is not only the language itself but the whole R ecosystem that surrounds it: the data types abstraction; the fact that can be run in interactive mode from a console, or by scripting automatic operations; the enormous plotting capabilities; its solid library of packages that always runs; that can easily integrate with lower level languages such as C, C++ or Fortran. R practically reads and writes any possible data format or database. 3.3 Ploting Plotting. The plotting capability is embedded in the base system itself. One of the major strengths is visualizing the data to make sense when there are millions and millions of numbers. No other language gets closer to that power. If you have tried C++, Python and Java you will have to end up searching for libraries and still will have to do a lot of leg work to get your plot right. Not in R. Besides the base plotting there are other powerful packages that even add a grammar of graphics such as ggplot2, which make R unique. 3.4 Packages Packages. Publishing a package in R, sort of has become a badge of honor due to the stringent requisites and numerous rules you have to comply with to make your package available to its repository CRAN. And I think for a good reason, R has kept kept solidly growing and giving reliable results. And it is on the subject of reliability where the major separation between R and Python starts. If there is something that the Python community has to do to is improving the reliability of the code. Maybe by centralizing the package development under more rigorous standards. Today, there is not only two major Python versions out there competing, 2.7 and 3.5, but package compatibility varies from distributor to distributor. An application developed using Python vendor X will not run without hiccups or crashing in A or E or vice versa. 3.5 Foreign languages Speaks C, C++ and Fortran. I think this is the one of the characteristics that caught more of my attention during my R exploration. If there is a challenge in engineering, it is to make the applications faster and more efficient. C++ and Fortran bring that besides the enormous baggage of scientific libraries; proven and tested. I tried it with calls from R to C, C++ and Fortran and they just work without touching your settings in the operating system. I tried in Windows, Linux and Mac OSX, and all of them compile without needing an IT guy or Admin on your side. R makes an amazing engineering tool. I even tested calling math libraries in Java. 3.6 Reproducible Reproducible. This is a concept we may not have seen often in the petroleum industry. And that is possible due to our extreme reliance on spreadsheets. Everybody likes getting quick results. Don’t get me wrong. But the same characteristic of formulas and cells that made the worksheet the king, it is at the same time, its weakness. You cannot replicate safely the results unless you look at and revise cell by cell. You will never be sure that nothing has been improperly copied and pasted. And that’s a big problem. Spreadsheets nurtures bad data habits. I think it is here where the great influence of biomedicine, biogenetics, biogenomics and similar branches of the bio sciences play a vital role because they cannot afford any mistakes. The work of a researcher has to be able to be reproduced by colleagues or third parties before publication of the conclusions. The whole R environment has been molded in that way. The results should be the same -based on the same data-, regardless of who was the person running the analysis. Besides the benefit of repeating it in the future leaves lessons for others to learn. 3.7 GUI not No need for GUI. It must be the data-centric nature of R, and its focus on the statistics, that doesn’t make you miss a graphical user interface. So, let’s say you are tremendously happy that you can produce your analysis, plots and report that you forget that you need a window with buttons, dialogs or menus. You are busy with the data, the calculations, the algorithms and the statistics without paying attention to the bells and whistles of a fancy user interface (UI). The folks from RStudio -one of the R vendors-, came up with a beautiful model for the graphical interface, browser based, and its name is Shiny. I heard about it. Got worried: here comes another HTML, JavaScript, CSS tool to learn. Nope! Wrong! They have made possible an abstraction of the whole graphical construction to just simple use of R code. I remember producing my first graphical statistical application, with sliders and all, in approximately 5 minutes. It’s easy even if you don’t know much R; like I was few months ago. img 3.8 Where is everybody Why not everybody is using R then? R is hard. It looks different because it does things differently. I remember taking a look at my first book of R and thinking “rather do then my project in Python …” R exhibits a unique level of abstraction when it comes to the way of manipulating the data; it doesn’t resembles much of Python, or much less of Visual Basic. The best and most efficient operations are performed using vectors and it is heavily discouraged -but not forbidden- to use loops to perform iterations. Rather be using apply, lapply, sapply or the other apply functions. Getting out of the loop - no pun intended - possibly, is one of bad habits harder to break. It takes a while to get accustomed to the functional programming demands of coding in **R. But it is neater and one gets amazed that one line of code can do so much to summarize a huge data table and replace nested “for” loops. 3.9 The bottom line The bottom line. R, and the other scripting languages available, will always make your engineering and data science results better, state-of-art, reproducible, shareable, version-controlled, with publishing quality and with much, much better plots than the canned worksheet graphics, which by the way, haven’t changed much for the past 25 years. You can follow me via Twitter via fonzie@OilGains "]
]
